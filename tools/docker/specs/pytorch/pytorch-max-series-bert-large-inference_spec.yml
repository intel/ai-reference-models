releases:
  versioned:
    tag_specs:
    - '{pytorch-ipex-max-series-base-public}{pytorch-max-series-bert-large-inference}'
slice_sets:
  pytorch-max-series-bert-large-inference:
  - add_to_name: pytorch-max-series-bert-large-inference
    dockerfile_exclusive_name: -bert-large-inference
    args:
    - PACKAGE_NAME=pytorch-max-series-bert-large-inference
    dockerfile_subdirectory: gpu_model_containers
    downloads: []
    files:
    - source: quickstart/language_modeling/pytorch/bert_large/inference/gpu/README.md
      destination: README.md
    - destination: models/language_modeling/pytorch/bert_large/inference/gpu
      source: models/language_modeling/pytorch/bert_large/inference/gpu
    - source: models/language_modeling/pytorch/bert_large/inference/gpu/requirements.txt
      destination: requirements.txt
    - destination: quickstart/fp16_inference_block_format.sh
      source: quickstart/language_modeling/pytorch/bert_large/inference/gpu/fp16_inference_block_format.sh
    - destination: quickstart/fp16_inference_plain_format.sh
      source: quickstart/language_modeling/pytorch/bert_large/inference/gpu/fp16_inference_plain_format.sh
    - destination: quickstart/fp32_fine_tuning_accuracy.sh
      source: quickstart/language_modeling/pytorch/bert_large/inference/gpu/fp32_fine_tuning_accuracy.sh
    - destination: quickstart/fp32_inference.sh
      source: quickstart/language_modeling/pytorch/bert_large/inference/gpu/fp32_inference.sh
    - source: quickstart/common/pytorch/gpu/setvars.sh
      destination: quickstart/setvars.sh
    wrapper_package_files:
     - source: quickstart/language_modeling/pytorch/bert_large/inference/gpu/build.sh
       destination: build.sh
     - source: dockerfiles/gpu_model_containers/pytorch-max-series-bert-large-inference.Dockerfile
       destination: pytorch-max-series-bert-large-inference.Dockerfile
     - source: output/pytorch-max-series-bert-large-inference.tar.gz
       destination: model_packages/pytorch-max-series-bert-large-inference.tar.gz
     - source: ""
       destination: info.txt
     - source: third_party
       destination: licenses/third_party
     - source: LICENSE
       destination: licenses/LICENSE
    partials:
    - model_package
    - pytorch/bert-inference-installs
    - entrypoint
