releases:
  versioned:
    tag_specs:
    - '{ipex-centos-dlrm-base}{icx-dlrm-fp32}'
slice_sets:
  ipex-centos-dlrm-base:
  - add_to_name: "ipex-centos"
    partials:
      - pytorch/ipex-centos-icx-dlrm-base
    args:
        - IPEX_CONTAINER_TAG=intel/recommendation:pytorch-1.5.0-rc3-icx-a37fb5e8
  icx-dlrm-fp32:
  - add_to_name: -icx-dlrm-fp32
    args:
    - PACKAGE_NAME=icx-dlrm-fp32-inference
    dockerfile_subdirectory: pytorch
    downloads: []
    documentation:
      - docs:
        - name: Title
          uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32/.docs/title.md
        - name: Description
          uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32/.docs/description.md
        - name: Datasets
          uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32/.docs/datasets.md
        - name: Quick Start Scripts
          uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32/.docs/quickstart.md
        - name: Docker
          uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32/.docs/docker.md
        - name: License
          uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32/.docs/license.md
        name: README.md
        uri: models/quickstart/ipex-bkc/dlrm-icx/inference/fp32
    files:
    - destination: quickstart/vanilla_inference_latency.sh
      source: quickstart/ipex-bkc/dlrm-icx/inference/fp32/vanilla_inference_latency.sh
    - destination: quickstart/ipex_inference_latency.sh
      source: quickstart/ipex-bkc/dlrm-icx/inference/fp32/ipex_inference_latency.sh
    - destination: quickstart/inference_accuracy.sh
      source: quickstart/ipex-bkc/dlrm-icx/inference/fp32/inference_accuracy.sh
    - destination: quickstart/dlrm
      source: models/recommendation/pytorch/dlrm/inference
    partials:
    - model_package
    - entrypoint-centos
