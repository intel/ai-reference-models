inference-fp16:
  cmd:
    bash $GITHUB_WORKSPACE/tests/cicd/pytorch/pyt_xpu_setup.sh ${FRAMEWORK_VERSION} ${FRAMEWORK_EXTENSION_VERSION} ${IS_LKG_DROP} ${AIKIT_VERSION};
    bash $GITHUB_WORKSPACE/tests/cicd/pytorch/stable_diffusion/inference/gpu/test_model.sh ${PRECISION} ${IS_LKG_DROP} ${RUNNER} ${MULTI_TILE}
  env:
    PRECISION: "fp16"
    MULTI_TILE: "False"
inference-fp32:
  cmd:
    bash $GITHUB_WORKSPACE/tests/cicd/pytorch/pyt_xpu_setup.sh ${FRAMEWORK_VERSION} ${FRAMEWORK_EXTENSION_VERSION} ${IS_LKG_DROP} ${AIKIT_VERSION};
    bash $GITHUB_WORKSPACE/tests/cicd/pytorch/stable_diffusion/inference/gpu/test_model.sh ${PRECISION} ${IS_LKG_DROP} ${RUNNER} ${MULTI_TILE}
  env:
    PRECISION: "fp32"
    MULTI_TILE: "False"
inference-fp16-multi:
  cmd:
    bash $GITHUB_WORKSPACE/tests/cicd/pytorch/pyt_xpu_setup.sh ${FRAMEWORK_VERSION} ${FRAMEWORK_EXTENSION_VERSION} ${IS_LKG_DROP} ${AIKIT_VERSION};
    bash $GITHUB_WORKSPACE/tests/cicd/pytorch/stable_diffusion/inference/gpu/test_model.sh ${PRECISION} ${IS_LKG_DROP} ${RUNNER} ${MULTI_TILE}
  env:
    PRECISION: "fp16"
    MULTI_TILE: "True"
inference-fp32-multi:
  cmd:
    bash $GITHUB_WORKSPACE/tests/cicd/pytorch/pyt_xpu_setup.sh ${FRAMEWORK_VERSION} ${FRAMEWORK_EXTENSION_VERSION} ${IS_LKG_DROP} ${AIKIT_VERSION};
    bash $GITHUB_WORKSPACE/tests/cicd/pytorch/stable_diffusion/inference/gpu/test_model.sh ${PRECISION} ${IS_LKG_DROP} ${RUNNER} ${MULTI_TILE}
  env:
    PRECISION: "fp32"
    MULTI_TILE: "True"
