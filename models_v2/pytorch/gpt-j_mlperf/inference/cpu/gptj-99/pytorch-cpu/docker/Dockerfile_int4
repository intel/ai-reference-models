# syntax = docker/dockerfile:experimental
# based onhttps://github.com/pytorch/pytorch/blob/master/Dockerfile
# 
# NOTE: To build this you will need a docker version > 18.06 with
#       experimental enabled and DOCKER_BUILDKIT=1
#
#       If you do not use buildkit you are not going to have a good time
#
#       For reference: 
#           https://docs.docker.com/develop/develop-images/build_enhancements/
#
# Copyright (c) 2023 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
ARG BENCHMARK=gptj-99
ARG IMPL=pytorch-cpu
ARG BASE_IMAGE=ubuntu:22.04
FROM ${BASE_IMAGE} AS dev-base
RUN apt-get update && apt-get upgrade -y && \
    DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \
    ca-certificates \
    git \
    vim \
    numactl \
    cmake \
    wget \
    findutils \
    build-essential \
    sudo \
    gcc-12 \
    g++-12 \
    libzstd-dev \
    libgtk2.0-dev \
    libgl1 \
    libxml2-dev \
    zlib1g-dev \
    libdata-dumper-simple-perl \
    && rm -rf /var/lib/apt/lists/* && \
    update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 && \
    update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-12 10 && \ 
    update-alternatives --set gcc "/usr/bin/gcc-12" && \
    update-alternatives --set g++ "/usr/bin/g++-12"
RUN echo "alias ll='ls -l'" >> /root/.bashrc
ENV PATH /opt/conda/bin:$PATH

FROM dev-base as conda
ARG PYTHON_VERSION=3.9
RUN wget -O ~/miniforge.sh https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh  && \
    chmod +x ~/miniforge.sh && \
    ~/miniforge.sh -b -p /opt/conda && \
    rm ~/miniforge.sh && \
    /opt/conda/bin/conda install python=${PYTHON_VERSION} -y && \
    /opt/conda/bin/conda config --add channels intel && \
    /opt/conda/bin/conda install -c intel mkl==2023.2.0 mkl-include==2023.2.0 -y && \
    /opt/conda/bin/conda install -c conda-forge jemalloc==5.2.1 gperftools==2.10 pybind11==2.10.4 llvm-openmp==16.0.6 -y && \
    /opt/conda/bin/conda install -c intel intel-openmp==2022.2.1 --yes && \
    /opt/conda/bin/conda install -c conda-forge gcc==12.3 gxx==12.3 cxx-compiler==1.7.0 ninja==1.11.1 zlib==1.2.13 -y && \
    /opt/conda/bin/conda install conda-forge::sysroot_linux-64==2.28 -y && \
    #/opt/conda/bin/conda install -c conda-forge libstdcxx-ng=12.3.0 -y && \
    /opt/conda/bin/conda clean -ya  && \
    export CC=`which gcc` && export CXX=`which g++` && \
    pip install setuptools==60.0.0 && \
    pip install cmake==3.27.0 cpuid==0.0.11 nltk==3.8.1 evaluate==0.4.0 protobuf==3.20.3 absl-py==1.4.0 && \
    pip install rouge-score==0.1.2 tqdm==4.65.0 numpy==1.25.2 cython==3.0.0 sentencepiece==0.1.99 accelerate==0.21.0 && \
    pip install neural_compressor==2.4.1 && \
    pip install transformers==4.36.2

FROM conda AS build
ARG BENCHMARK
ARG IMPL
COPY --from=conda /opt/conda /opt/conda
WORKDIR /opt/workdir
COPY ./cpu/${BENCHMARK} code/${BENCHMARK}
COPY ./cpu/run_clean.sh code/${BENCHMARK}/${IMPL}/run_clean.sh
COPY ./cpu/user_config.py code/user_config.py
COPY ./cpu/calibration/${BENCHMARK} calibration/${BENCHMARK}
ARG PYTORCH_COMMIT=4e2aa5dbb86610854f7d42ded4488f6cb1845be6
ARG IPEX_COMMIT=6047b5410bc8d7ad3a0d9e60acd74d924ae6f676
ENV CONDA_PREFIX "/opt/conda"
RUN update-ca-certificates -f && \
    cd /opt/workdir/code/${BENCHMARK}/${IMPL} && mkdir gpt-j-env && cd gpt-j-env && \
    git clone https://github.com/pytorch/pytorch.git pytorch && cd pytorch && \
    git checkout ${PYTORCH_COMMIT} && git submodule sync && git submodule update --init --recursive && \
    export CMAKE_PREFIX_PATH=${CONDA_PREFIX:-"$(dirname $(which conda))/../"} && \
    export _GLIBCXX_USE_CXX11_ABI=1 && export CXXFLAGS="${CXXFLAGS} -Wno-nonnull" && \
    export LD_LIBRARY_PATH=${CONDA_PREFIX}/lib:${LD_LIBRARY_PATH} && \
    export LIBRARY_PATH=${CONDA_PREFIX}/lib:${LIBRARY_PATH} && \
    python setup.py install && python setup.py develop && cd .. && \
    cd /opt/workdir/code/${BENCHMARK}/${IMPL}/gpt-j-env && \
    git clone https://github.com/intel/intel-extension-for-pytorch ipex-cpu && cd ipex-cpu && \
    git checkout ${IPEX_COMMIT} && git submodule sync && git submodule update --init --recursive && \
    export CXXFLAGS="${CXXFLAGS} -D__STDC_FORMAT_MACROS" && export _GLIBCXX_USE_CXX11_ABI=1 && \
    python setup.py install && python setup.py develop && cd .. && \
    git clone https://github.com/mlcommons/inference.git mlperf_inference && \
    cd mlperf_inference && \
    cp mlperf.conf ../../ && \
    export MLPERF_INFERENCE_ROOT=${PWD} && \
    git submodule update --init --recursive && \
    cd loadgen && \
    python -m pip install . && \
    cd /opt/workdir/code/${BENCHMARK}/${IMPL}/utils && \
    python -m pip install .

ENV LD_LIBRARY_PATH "/opt/conda/lib:${LD_LIBRARY_PATH}"
FROM dev-base as mp
COPY --from=build /opt/conda /opt/conda
COPY --from=build /opt/workdir /opt/workdir
WORKDIR /opt/workdir
ENV CONDA_PREFIX "/opt/conda"
