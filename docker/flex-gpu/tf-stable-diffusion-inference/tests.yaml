---
fp32-online-inference:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-generative-ai-tf-flex-gpu-stable-diffusion-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  env:
    PRECISION: fp32
    OUTPUT_DIR: /tmp
fp16-online-inference:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-generative-ai-tf-flex-gpu-stable-diffusion-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  env:
    PRECISION: fp16
    OUTPUT_DIR: /tmp
