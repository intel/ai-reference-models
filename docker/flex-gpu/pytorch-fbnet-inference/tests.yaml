# Copyright (c) 2023-2024 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#Initial test. Will catch any global issues.
#Unique coverage: Tests BATCH_SIZE 1 case. Will test multiple batches (NUM_INPUTS // BATCH_SIZE)
bs001-s1-bf16amp-jittrace-c100:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-flex-gpu-fbnet-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  cap_add: SYS_NICE
  env:
    BATCH_SIZE: '1'
    STREAMS: '1'
    MODEL_NAME: 'fbnetc_100'
    NUM_INPUTS: '64'
    DUMMY: 'yes'
    PRECISION: 'bf16'
    AMP: 'yes'
    JIT: 'trace'
    OUTPUT_DIR: '/tmp'
  volumes:
    - src: /tmp
      dst: /tmp
#Initial test with BATCH_SIZE greater than 1.
#Unique coverage: None, just baseline on BATCH_SIZE > 1
bs064-s1-bf16amp-jittrace-c100:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-flex-gpu-fbnet-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  cap_add: SYS_NICE
  env:
    BATCH_SIZE: '64'
    STREAMS: '1'
    MODEL_NAME: 'fbnetc_100'
    NUM_INPUTS: '64'
    DUMMY: 'yes'
    PRECISION: 'bf16'
    AMP: 'yes'
    JIT: 'trace'
    OUTPUT_DIR: '/tmp'
  volumes:
    - src: /tmp
      dst: /tmp
#Initial test with BATCH_SIZE greater than NUM_INPUTS.
#Unique coverage: NUM_INPUTS should be increased internally to be at least equal to BATCH_SIZE
bs256-s1-bf16amp-jittrace-c100:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-flex-gpu-fbnet-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  cap_add: SYS_NICE
  env:
    BATCH_SIZE: '256'
    STREAMS: '1'
    MODEL_NAME: 'fbnetc_100'
    NUM_INPUTS: '64'
    DUMMY: 'yes'
    PRECISION: 'bf16'
    AMP: 'yes'
    JIT: 'trace'
    OUTPUT_DIR: '/tmp'
  volumes:
    - src: /tmp
      dst: /tmp
#Initial test with STREAMS greater than 1.
#Unique coverage: STREAMS equal to 2
bs064-s2-bf16amp-jittrace-c100:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-flex-gpu-fbnet-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  cap_add: SYS_NICE
  env:
    BATCH_SIZE: '64'
    STREAMS: '2'
    MODEL_NAME: 'fbnetc_100'
    NUM_INPUTS: '64'
    DUMMY: 'yes'
    PRECISION: 'bf16'
    AMP: 'yes'
    JIT: 'trace'
    OUTPUT_DIR: '/tmp'
  volumes:
    - src: /tmp
      dst: /tmp
#More streams than previous test. Previous test was a multi-stream baseline. This is to stress it (moderately).
#Unique coverage: STREAMS equal to 4
bs064-s4-bf16amp-jittrace-c100:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-flex-gpu-fbnet-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  cap_add: SYS_NICE
  env:
    BATCH_SIZE: '64'
    STREAMS: '4'
    MODEL_NAME: 'fbnetc_100'
    NUM_INPUTS: '64'
    DUMMY: 'yes'
    PRECISION: 'bf16'
    AMP: 'yes'
    JIT: 'trace'
    OUTPUT_DIR: '/tmp'
  volumes:
    - src: /tmp
      dst: /tmp
#Initial test with PRECISION equal to FP16.
#Unique coverage: PRECISION equal to FP16
bs064-s1-fp16amp-jittrace-c100:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-flex-gpu-fbnet-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  cap_add: SYS_NICE
  env:
    BATCH_SIZE: '64'
    STREAMS: '1'
    MODEL_NAME: 'fbnetc_100'
    NUM_INPUTS: '64'
    DUMMY: 'yes'
    PRECISION: 'fp16'
    AMP: 'yes'
    JIT: 'trace'
    OUTPUT_DIR: '/tmp'
  volumes:
    - src: /tmp
      dst: /tmp
#Initial test with PRECISION equal to FP32.
#Unique coverage: PRECISION equal to FP32
bs064-s1-fp32amp-jittrace-c100:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-flex-gpu-fbnet-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  cap_add: SYS_NICE
  env:
    BATCH_SIZE: '64'
    STREAMS: '1'
    MODEL_NAME: 'fbnetc_100'
    NUM_INPUTS: '64'
    DUMMY: 'yes'
    PRECISION: 'fp32'
    AMP: 'yes'
    JIT: 'trace'
    OUTPUT_DIR: '/tmp'
  volumes:
    - src: /tmp
      dst: /tmp
#Initial test with AMP disabled
#Unique coverage: Only test with jit trace and no amp
bs064-s1-bf16noamp-jittrace-c100:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-flex-gpu-fbnet-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  cap_add: SYS_NICE
  env:
    BATCH_SIZE: '64'
    STREAMS: '1'
    MODEL_NAME: 'fbnetc_100'
    NUM_INPUTS: '64'
    DUMMY: 'yes'
    PRECISION: 'bf16'
    AMP: 'no'
    JIT: 'trace'
    OUTPUT_DIR: '/tmp'
  volumes:
    - src: /tmp
      dst: /tmp
#Initial test with JIT set to script
#Unique coverage: Only test with jit script and amp
bs064-s1-bf16amp-jitscript-c100:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-flex-gpu-fbnet-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  cap_add: SYS_NICE
  env:
    BATCH_SIZE: '64'
    STREAMS: '1'
    MODEL_NAME: 'fbnetc_100'
    NUM_INPUTS: '64'
    DUMMY: 'yes'
    PRECISION: 'bf16'
    AMP: 'yes'
    JIT: 'script'
    OUTPUT_DIR: '/tmp'
  volumes:
    - src: /tmp
      dst: /tmp
#Initial test with JIT set to script and AMP set to no
#Unique coverage: Only test with jit script and no amp
bs064-s1-bf16noamp-jitscript-c100:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-flex-gpu-fbnet-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  cap_add: SYS_NICE
  env:
    BATCH_SIZE: '64'
    STREAMS: '1'
    MODEL_NAME: 'fbnetc_100'
    NUM_INPUTS: '64'
    DUMMY: 'yes'
    PRECISION: 'bf16'
    AMP: 'no'
    JIT: 'script'
    OUTPUT_DIR: '/tmp'
  volumes:
    - src: /tmp
      dst: /tmp
#Initial test model save
#Unique coverage: Nothing unique. Just baseline for subsequent test.
bs064-s1-bf16amp-jittrace-c100-save:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-flex-gpu-fbnet-inference
  cmd: bash run_model.sh --save saved_model.pt
  ipc: host
  device: /dev/dri
  cap_add: SYS_NICE
  env:
    BATCH_SIZE: '64'
    STREAMS: '1'
    MODEL_NAME: 'fbnetc_100'
    NUM_INPUTS: '64'
    DUMMY: 'yes'
    PRECISION: 'bf16'
    AMP: 'yes'
    JIT: 'trace'
    OUTPUT_DIR: '/tmp'
#Initial test model load
#Unique coverage: Complete model save and then model load.
bs064-s1-bf16amp-jittrace-c100-saveandload:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-flex-gpu-fbnet-inference
  cmd: bash -c "./run_model.sh --save saved_model.pt && ./run_model.sh --load saved_model.pt"
  ipc: host
  device: /dev/dri
  cap_add: SYS_NICE
  env:
    BATCH_SIZE: '64'
    STREAMS: '1'
    MODEL_NAME: 'fbnetc_100'
    NUM_INPUTS: '64'
    DUMMY: 'yes'
    PRECISION: 'bf16'
    AMP: 'yes'
    JIT: 'trace'
    OUTPUT_DIR: '/tmp'
  volumes:
    - src: /tmp
      dst: /tmp
#Initial test with test duration specified.
#Unique coverage: Sets min and max test duration to 10 seconds
bs001-s1-bf16amp-jittrace-bc00-td:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-flex-gpu-fbnet-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  cap_add: SYS_NICE
  env:
    BATCH_SIZE: '1'
    STREAMS: '1'
    MODEL_NAME: 'fbnetc_100'
    NUM_INPUTS: '64'
    MIN_TEST_DURATION: '10'
    MAX_TEST_DURATION: '10'
    DUMMY: 'yes'
    PRECISION: 'bf16'
    AMP: 'yes'
    JIT: 'trace'
    OUTPUT_DIR: '/tmp'
  volumes:
    - src: /tmp
      dst: /tmp
