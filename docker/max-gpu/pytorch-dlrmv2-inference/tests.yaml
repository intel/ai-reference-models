fp16-distributed-real-data-inference:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-recommendation-pytorch-max-gpu-dlrmv2-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  env:
    PRECISION: FP16
    BATCH_SIZE: '65536'
    OUTPUT_DIR: /tmp
    MULTI_TILE: 'True'
    PLATFORM: Max
    DATASET_DIR: /var/torchrec-dlrm-v2
    WEIGHT_DIR: /var/torchrec-dlrm-v2-weights
  volumes:
    - src: /var/torchrec-dlrm-v2
      dst: /var/torchrec-dlrm-v2
    - src: /dev/dri
      dst: /dev/dri
    - src: /var/torchrec-dlrm-v2-weights
      dst: /var/torchrec-dlrm-v2-weights
    - src: /tmp
      dst: /tmp
