fp32-inference:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-language-modeling-pytorch-max-gpu-distilbert-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  env:
    MULTI_TILE: 'True'
    PLATFORM: Max
    BATCH_SIZE: '32'
    OUTPUT_DIR: /tmp
    DATASET_DIR: /nfs/site/disks/mlp_pytorch_dataset/hdf5_seq_512/
    PRECISION: FP32
    NUM_ITERATIONS: '300'
  volumes:
    - src: /nfs/site/disks/mlp_pytorch_dataset/hdf5_seq_512/
      dst: /nfs/site/disks/mlp_pytorch_dataset/hdf5_seq_512/
    - src: /tmp
      dst: /tmp
fp16-inference:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-language-modeling-pytorch-max-gpu-distilbert-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  env:
    MULTI_TILE: 'True'
    PLATFORM: Max
    BATCH_SIZE: '32'
    OUTPUT_DIR: /tmp
    DATASET_DIR: /nfs/site/disks/mlp_pytorch_dataset/hdf5_seq_512/
    PRECISION: FP16
    NUM_ITERATIONS: '300'
  volumes:
    - src: /nfs/site/disks/mlp_pytorch_dataset/hdf5_seq_512/
      dst: /nfs/site/disks/mlp_pytorch_dataset/hdf5_seq_512/
    - src: /tmp
      dst: /tmp
bf16-inference:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-language-modeling-pytorch-max-gpu-distilbert-inference
  cmd: bash run_model.sh
  ipc: host
  device: /dev/dri
  env:
    MULTI_TILE: 'True'
    PLATFORM: Max
    BATCH_SIZE: '32'
    OUTPUT_DIR: /tmp
    DATASET_DIR: /nfs/site/disks/mlp_pytorch_dataset/hdf5_seq_512/
    PRECISION: BF16
    NUM_ITERATIONS: '300'
  volumes:
    - src: /nfs/site/disks/mlp_pytorch_dataset/hdf5_seq_512/
      dst: /nfs/site/disks/mlp_pytorch_dataset/hdf5_seq_512/
    - src: /tmp
      dst: /tmp
