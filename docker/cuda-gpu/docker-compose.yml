#
# -*- coding: utf-8 -*-
#
# Copyright (c) 2023 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

#

version: '1'
services:
  pytorch-efficientnet-inference:
    build:
      context: ../../
      args:
        http_proxy: ${http_proxy}
        https_proxy: ${https_proxy}
        no_proxy: ""
        NO_PROXY: ""
        CUDA_BASE_IMAGE: ${CUDA_BASE_IMAGE:-nvcr.io/nvidia/pytorch}
        CUDA_BASE_TAG: ${CUDA_BASE_TAG:-24.01-py3}
      dockerfile: docker/cuda-gpu/pytorch-efficientnet-inference/pytorch-cuda-series-efficientnet-inference.Dockerfile
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-cuda-gpu-efficientnet-inference
    pull_policy: always
  pytorch-yolov5-inference:
    build:
      dockerfile: docker/cuda-gpu/pytorch-yolov5-inference/pytorch-cuda-series-yolov5-inference.Dockerfile
    extends: pytorch-efficientnet-inference
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-object-detection-pytorch-cuda-gpu-yolov5-inference
    pull_policy: always
  pytorch-ifrnet-inference:
    build:
      dockerfile: docker/cuda-gpu/pytorch-ifrnet-inference/pytorch-cuda-series-ifrnet-inference.Dockerfile
    extends: pytorch-efficientnet-inference
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-interpolation-pytorch-cuda-gpu-ifrnet-inference
  pytorch-rife-inference:
    build:
      dockerfile: docker/cuda-gpu/pytorch-rife-inference/pytorch-cuda-series-rife-inference.Dockerfile
    extends: pytorch-efficientnet-inference
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-interpolation-pytorch-cuda-gpu-rife-inference
  pytorch-fbnet-inference:
    build:
      dockerfile: docker/cuda-gpu/pytorch-fbnet-inference/pytorch-cuda-series-fbnet-inference.Dockerfile
    extends: pytorch-efficientnet-inference
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-image-recognition-pytorch-cuda-gpu-fbnet-inference
