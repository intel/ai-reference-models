#
# -*- coding: utf-8 -*-
#
# Copyright (c) 2023 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
version: '3'
services:
  bert-large-inference:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-bert-large-inference
    pull_policy: always
    build:
      context: ../../
      args:
        http_proxy: ${http_proxy}
        https_proxy: ${https_proxy}
        no_proxy: ${no_proxy}
        BASE_IMAGE: intel/intel-extension-for-pytorch
        BASE_TAG: 2.3.0-pip-base
      dockerfile: docker/pyt-cpu/bert-large-inference/pytorch-bert-large-inference.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  maskrcnn-inference:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-object-detection-maskrcnn-inference
    pull_policy: always
    build:
      context: ../../
      dockerfile: docker/pyt-cpu/maskrcnn-inference/pytorch-maskrcnn-inference.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-inference
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  maskrcnn-training:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-object-detection-maskrcnn-training
    pull_policy: always
    build:
      context: ../../
      dockerfile: docker/pyt-cpu/maskrcnn-training/pytorch-maskrcnn-training.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-inference
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  resnet50-training:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-pytorch-image-recognition-resnet50-training
    pull_policy: always
    build:
      context: ../../
      dockerfile: docker/pyt-cpu/resnet50-training/pytorch-resnet50-training.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-inference
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  resnet50-inference:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-pytorch-image-recognition-resnet50-inference
    pull_policy: always
    build:
      context: ../../
      dockerfile: docker/pyt-cpu/resnet50-inference/pytorch-resnet50-inference.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-inference
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  ssd-resnet34-inference:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-object-detection-ssd-resnet34-inference
    pull_policy: always
    build:
      context: ../../
      dockerfile: docker/pyt-cpu/ssd-resnet34-inference/pytorch-ssd-resnet34-inference.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-inference
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  ssd-resnet34-training:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-object-detection-ssd-resnet34-training
    pull_policy: always
    build:
      context: ../../
      dockerfile: docker/pyt-cpu/ssd-resnet34-training/pytorch-ssd-resnet34-training.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-inference
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  dlrm-inference:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-recommendation-dlrm-inference
    pull_policy: always
    build:
      context: ../../
      dockerfile: docker/pyt-cpu/dlrm-inference/pytorch-dlrm-inference.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-inference
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  dlrm-training:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-recommendation-dlrm-training-${BASE_IMAGE_NAME:-ubuntu}
    pull_policy: always
    build:
      context: ../../
      dockerfile: docker/pyt-cpu/dlrm-training/pytorch-dlrm-training.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-inference
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  rnnt-training:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-rnnt-training
    pull_policy: always
    build:
      context: ../../
      dockerfile: docker/pyt-cpu/rnnt-training/pytorch-rnnt-training.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-inference
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  rnnt-inference:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-rnnt-inference
    pull_policy: always
    build:
      context: ../../
      dockerfile: docker/pyt-cpu/rnnt-inference/pytorch-rnnt-inference.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-inference
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  distilbert-inference:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
    pull_policy: always
    build:
      context: ../../
      dockerfile: docker/pyt-cpu/distilbert-inference/pytorch-distilbert-inference.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-inference
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  bert-large-training:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-bert-large-training
    pull_policy: always
    build:
      context: ../../
      dockerfile: docker/pyt-cpu/bert-large-training/pytorch-bert-large-training.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-inference
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  llama-inference:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-llama-inference
    pull_policy: always
    build:
      context: ../../
      args:
        BASE_IMAGE: ${REGISTRY}/aiops/mlops
        BASE_TAG: srf-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-pyt-2.3-py310
      dockerfile: docker/pyt-cpu/llama-inference/pytorch-llama-inference.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-training
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  dlrm-v2-inference:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-recommendation-dlrm-v2-inference
    pull_policy: always
    build:
      context: ../../
      args:
        BASE_IMAGE: ${REGISTRY}/aiops/mlops
        BASE_TAG: srf-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-pyt-2.3-py310
      dockerfile: docker/pyt-cpu/dlrm-v2-inference/pytorch-dlrm-v2-inference.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-training
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  gpt-j-inference:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-gpt-j-inference
    pull_policy: always
    build:
      context: ../../
      args:
        BASE_IMAGE: ${REGISTRY}/aiops/mlops
        BASE_TAG: srf-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-pyt-2.3-py310
      dockerfile: docker/pyt-cpu/gpt-j-inference/pytorch-gpt-j-inference.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-training
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
  yolov7-inference:
    image: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-object-detection-yolov7-inference
    pull_policy: always
    build:
      context: ../../
      args:
        BASE_IMAGE: ${REGISTRY}/aiops/mlops
        BASE_TAG: srf-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-pyt-2.3-py310
      dockerfile: docker/pyt-cpu/yolov7-inference/pytorch-yolov7-inference.Dockerfile-${BASE_IMAGE_NAME:-ubuntu}
    extends: bert-large-training
    command: >
      bash -c "python -c 'import torch; import intel_extension_for_pytorch as ipex; print(\"torch:\", torch.__version__, \" ipex:\",ipex.__version__)'"
