# Copyright (c) 2020-2021 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================

ARG BASE_IMAGE="intel/intel-extension-for-pytorch"
ARG BASE_TAG="2.0.0-pip-base"

FROM ${BASE_IMAGE}:${BASE_TAG} AS intel-optimized-pytorch

WORKDIR /workspace/pytorch-rnnt-inference

RUN apt-get update && \
    apt-get install --no-install-recommends --fix-missing -y \
    build-essential \
    ca-certificates \
    git \
    wget \
    make \
    cmake>=3.19.6 \
    autoconf \
    bzip2 \
    tar

RUN git clone  https://github.com/jemalloc/jemalloc.git && \
    cd jemalloc && \
    git checkout c8209150f9d219a137412b06431c9d52839c7272 && \
    ./autogen.sh && \
    ./configure --prefix=/workspace/lib/jemalloc && \
    make && \
    make install 

COPY models/language_modeling/pytorch/rnnt/inference/cpu models/language_modeling/pytorch/rnnt/inference/cpu
COPY quickstart/language_modeling/pytorch/rnnt/inference/cpu/enable_warprnnt_c++17.diff quickstart/enable_warprnnt_c++17.diff
COPY quickstart/language_modeling/pytorch/rnnt/inference/cpu/inference_realtime.sh quickstart/inference_realtime.sh 
COPY quickstart/language_modeling/pytorch/rnnt/inference/cpu/inference_throughput.sh quickstart/inference_throughput.sh
COPY quickstart/language_modeling/pytorch/rnnt/inference/cpu/accuracy.sh quickstart/accuracy.sh
COPY  quickstart/language_modeling/pytorch/rnnt/inference/cpu/download_dataset.sh quickstart/download_dataset.sh

RUN cd /workspace/pytorch-rnnt-inference/models/language_modeling/pytorch/rnnt/inference/cpu && \
    pip install -r requirements.txt && \
    pip install unidecode inflect && \
    apt-get update && apt-get install -y gcc python3.10-dev && \
    git clone https://github.com/HawkAaron/warp-transducer && \
    cd warp-transducer && \
    git checkout master && \
    git apply /workspace/pytorch-rnnt-inference/quickstart/enable_warprnnt_c++17.diff && \
    mkdir build && \
    cd build && \
    cmake .. && \
    make && \
    cd ../pytorch_binding && \
    python setup.py install

RUN pip install packaging intel-openmp librosa==0.9.1

ENV LD_PRELOAD="/workspace/lib/jemalloc/lib/libjemalloc.so":"/usr/local/lib/libiomp5.so":$LD_PRELOAD 
ENV MALLOC_CONF="oversize_threshold:1,background_thread:true,metadata_thp:auto,dirty_decay_ms:9000000000,muzzy_decay_ms:9000000000"

RUN apt-get update && \
    apt-get install --no-install-recommends --fix-missing -y \
      numactl \
      libegl1-mesa 

COPY LICENSE licenses/LICENSE
COPY third_party licenses/third_party
